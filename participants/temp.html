<main><div class="hero"><br></br><br></br><header><div class="speaker-img" style="background-image: url(/images/Headshot/R_1eVjAnmbkWOOE5l_WX20231106-232857@2x-min.png);"></div><div><h1>Jiao Sun</h1><ul class="socials"><li><b>Position: </b><a>PhD Candidate   </a><b>Institution: </b><a>University of Southern California</a></li></ul></div></header></div><section class="speaker"><header><h2><b>Emphasizing the Role of Data and Evaluation in the Era of Large Models</b></h2></header><div classs="hero"><br></br><h3 id="eligibility"><b>Research Abstract:</b></h3><p>With the rapid advancement and proliferation of large models, they are becoming ubiquitous, reaching beyond the academic sphere to affect the daily lives of both researchers and the general public. Yet, the pivotal role of data and evaluation in the development of generative models remains underestimated. Recent of my works center around refining text evaluation metrics by leveraging pre-existing corpora for pretraining and using these metrics to further enhance the model performance.</p><h3 id="eligibility"><b>Bio:</b></h3><p>Jiao Sun is a final-year Ph.D. candidate and an Amazon Fellow at the University of Southern California. Her research is centered around trustworthy natural language generation &#8212; ranging from the construction of controlled text generation models to the formulation of generation evaluation metrics. Her influential works have been showcased at premier conferences like ACL, EMNLP, NAACL, and CHI, with accolades that include a best paper honorable mention at CHI and a best paper nomination at ACL. Furthermore, she has interned at Google DeepMind, Amazon Alexa AI, and IBM Research. Discover more about Jiao at https://sunjiao123sun.github.io/.</p></div></section></main>